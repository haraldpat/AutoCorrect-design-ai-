{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoCorrect Tool\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motive: Whenever a word is typed we need to check the word and auto correct it if it's mispelled. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HOW?\n",
    "###### Approach 1\n",
    "We can make use of **\"Edit Distance\"**.\n",
    "\"Edit distance\" is a string metric, i.e. a way of quantifying how dissimilar two strings (e.g., words) are to one another, that is measured by counting the minimum number of operations required to transform one string into the other.\n",
    "We can create a group of correct words(dictionary) and when the test word finds the distances from all the words in dictionary and replaces it with the word having minimum distance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of **Levenshtein distance**.\n",
    "Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Levenshtein distance between two words\n",
    "def editDistance(s: str, t: str) -> int:\n",
    "    n = len(s)\n",
    "    m = len(t)\n",
    "\n",
    "    prev = [j for j in range(m+1)]\n",
    "    curr = [0] * (m+1)\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        curr[0] = i\n",
    "        for j in range(1, m+1):\n",
    "            if s[i-1] == t[j-1]:\n",
    "                curr[j] = prev[j-1]\n",
    "            else:\n",
    "                mn = min(1 + prev[j], 1 + curr[j-1])\n",
    "                curr[j] = min(mn, 1 + prev[j-1])\n",
    "        prev = curr.copy()\n",
    "\n",
    "    return prev[m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list calculating the word's distance from every other words in the dictionary\n",
    "def find_word(diction: list,word: str) -> list:\n",
    "    final=[]\n",
    "    for w in diction:\n",
    "        final.append(editDistance(w,word))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Before: I am hapu to sve ths county from rage spleling\n",
      "Text After: I am happy to save this country from rage spelling \n"
     ]
    }
   ],
   "source": [
    "diction = [\"save\",\"happy\",\"I\",\"want\",\"realistic\",\"this\",\"intuitive\",\"from\",\"to\",\"am\",\"rage\",\"spell\",\"check\",\"fortune\",\"resonance\",\"spelling\",\"country\",\"Please\",\"is\",\"a\"]\n",
    "text = \"I am hapu to sve ths county from rage spleling\"\n",
    "text2=text.split(\" \");\n",
    "ans=\"\"\n",
    "for word in text2:\n",
    "    dist_word = find_word(diction,word)\n",
    "    fword = diction[dist_word.index(min(dist_word))]\n",
    "    ans = ans+fword+\" \"\n",
    "print(\"Text Before: \"+text)\n",
    "print(\"Text After: \"+ans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUt this approach has many limitations in real world:\n",
    "(1) **Takes much time and space**\n",
    "Time Complexity: O(len(word) x len(dictionary))\n",
    "Space Complexity: O(len(Dictionary))\n",
    "And dictionary needs to be huge to encompass all the english words.\n",
    "(2) **Many words may have same minimum distance and so it becomes to difficult to choose which word is optimal to choose**\n",
    "(3) **It also becomes difficult to choose words in which context is the sentence being written**\n",
    "There can be chance that the desired word was not one with the minimum Levenshtein distance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach 2\n",
    "Now the previous approach gave us some lead to find the close words which the user might want to type, but which word he/she wants, this can be done by seeing their previous words which has been written and make a probabilistic assumptions from that probability list. This is an excellent application of A.I. specifically learning from the past experiences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving to more further implementation, we would see another sort of string comparing method known as jacard index, it measures the similarity between two words and this can be helpful as to predict the word here. A very useful library text distance has many of this string matching algorithm, thus we can make use of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.25.1)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install textdistance\n",
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtextdistance\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     fd \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     fd\u001b[39m=\u001b[39mfd\u001b[39m.\u001b[39mlower()\n\u001b[1;32m----> 5\u001b[0m     words \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m'\u001b[39m,fd)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Dictionary(VAcabulary) of words present in text\u001b[39;00m\n\u001b[0;32m      7\u001b[0m V \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(words)\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "with open('rtext.txt','r',encoding=\"utf8\") as f:\n",
    "    fd = f.read()\n",
    "    fd=fd.lower()\n",
    "    words = re.findall('\\w+',fd)\n",
    "# Dictionary(Vocabulary) of words present in text\n",
    "D = set(words)\n",
    "print(f\"Words in the text:{words[0:10]}\")\n",
    "print(f\"Total Unique words are {len(D)}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14703), ('of', 6742), ('and', 6517), ('a', 4799), ('to', 4707), ('in', 4238), ('that', 3081), ('it', 2534), ('his', 2530), ('i', 2120)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}  \n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in D:\n",
    "        return('Your word seems to be correct')\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=1).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        df['Similarity'] = sim\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>spell</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>pills</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16791</th>\n",
       "      <td>spill</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16963</th>\n",
       "      <td>pulls</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>spells</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word      Prob  Similarity\n",
       "3592    spell  0.000049    0.800000\n",
       "13391   pills  0.000009    0.800000\n",
       "16791   spill  0.000004    0.800000\n",
       "16963   pulls  0.000004    0.800000\n",
       "7958   spells  0.000004    0.666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"spll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
